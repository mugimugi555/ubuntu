#!/bin/bash

# ============================
# LoRA Training Shell Script
# venvã§ç’°å¢ƒç®¡ç† + ç”»åƒãƒªã‚µã‚¤ã‚º + LoRAå­¦ç¿’ (æ—¥æœ¬ãƒŸãƒ©ãƒ¼ & ä¸¦åˆ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾å¿œ)
# ============================

# è¨­å®š
VENV_DIR="venv-lora"  # ä»®æƒ³ç’°å¢ƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
BASE_DIR="dataset"  # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR="output_lora_model"  # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
IMAGE_SIZE=256  # ç”»åƒã®ã‚µã‚¤ã‚º (ç¸¦æ¨ªå…±é€š)
EPOCHS=10  # ã‚¨ãƒãƒƒã‚¯æ•°
BATCH_SIZE=1  # ãƒãƒƒãƒã‚µã‚¤ã‚º

# =====================
# ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# =====================
setup_environment() {
  echo "ğŸ”¹ ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯..."
  sudo apt update && sudo apt install -y python3 python3-venv python3-pip git imagemagick pipx

  echo "ğŸ”¹ ä»®æƒ³ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—: $VENV_DIR"
  if [ ! -d "$VENV_DIR" ]; then
    python3 -m venv "$VENV_DIR"
  fi
  source "$VENV_DIR/bin/activate"

  echo "ğŸ”¹ `uv` ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
  pipx install uv

  echo "ğŸ”¹ `uv` ã‚’ä½¿ç”¨ã—ã¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä¸¦åˆ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«..."
  env PIP_INDEX_URL="https://pypi.ngc.nvidia.com/simple" \
    uv pip install --upgrade pip && \
    uv pip install \
      "numpy<1.25.0" scipy torch torchvision torchaudio tensorboard \
      tensorflow accelerate transformers datasets matplotlib imagesize

  echo "âœ… ä»®æƒ³ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼"
}

# =====================
# äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å–å¾—
# =====================
download_pretrained_model() {
  if [ ! -d "stable-diffusion-v1-5" ]; then
    echo "ğŸ”¹ äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Hugging Face ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™..."
    git clone https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5
  else
    echo "âœ… äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚"
  fi
}

# =====================
# å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å–å¾—
# =====================
setup_training_repo() {
  if [ ! -d "sd-scripts" ]; then
    echo "ğŸ”¹ Kohyaâ€™s SS ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚GitHubã‹ã‚‰ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™..."
    git clone https://github.com/kohya-ss/sd-scripts.git
  else
    echo "âœ… å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚æœ€æ–°ã®çŠ¶æ…‹ã«æ›´æ–°ã—ã¾ã™..."
    cd "sd-scripts" && git pull && cd ..
  fi

  # `sd-scripts` ã® `requirements.txt` ã‚’ `uv` ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
  echo "ğŸ”¹ sd-scripts ã®ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
  # shellcheck disable=SC2164
  cd sd-scripts
  uv pip install -r requirements.txt
  cd ..
  echo "âœ… sd-scripts ã®ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ï¼"
}

# =====================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# =====================
setup_dataset() {
  if [ ! -d "$BASE_DIR" ]; then
    echo "âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $BASE_DIR"
    echo "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
    exit 1
  fi
  setup_captions
}
setup_captions() {
  FOLDER_NAME="Dariusz"
  for img in dataset/$FOLDER_NAME/*.{jpg,png}; do
    caption_file="${img%.*}.caption"
    if [ ! -f "$caption_file" ]; then
      echo "$FOLDER_NAME" > "$caption_file"
    fi
  done
  echo "âœ… ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã—ãŸã€‚"
}

# =====================
# ç”»åƒãƒªã‚µã‚¤ã‚ºå‡¦ç†
# =====================
resize_images() {
  echo "ğŸ”¹ ç”»åƒã‚’ ${IMAGE_SIZE}x${IMAGE_SIZE} ã«ãƒªã‚µã‚¤ã‚ºä¸­..."
  find "$BASE_DIR" -type f \( -iname "*.jpg" -o -iname "*.png" \) -exec mogrify -resize ${IMAGE_SIZE}x${IMAGE_SIZE}\! {} \;
  echo "âœ… ãƒªã‚µã‚¤ã‚ºå®Œäº†ï¼"
}

# =====================
# LoRA å­¦ç¿’ã®å®Ÿè¡Œ
# =====================
run_training() {

  echo "ğŸ”¹ LoRAå­¦ç¿’é–‹å§‹..."
  export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

  accelerate launch --mixed_precision="bf16" "sd-scripts/train_network.py" \
    --pretrained_model_name_or_path="stable-diffusion-v1-5" \
    --train_data_dir="$BASE_DIR" \
    --output_dir="$OUTPUT_DIR" \
    --resolution=$IMAGE_SIZE \
    --train_batch_size=$BATCH_SIZE \
    --max_train_epochs=$EPOCHS \
    --learning_rate=5e-6 \
    --network_module=networks.lora

  echo "âœ… å­¦ç¿’å®Œäº†ï¼ãƒ¢ãƒ‡ãƒ«ã¯ $OUTPUT_DIR ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚"
}

# =====================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =====================
main() {
  # ç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä»®æƒ³ç’°å¢ƒã®ä½œæˆãƒ»ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰
  setup_environment

  # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆsd-scriptsï¼‰ã®å–å¾—ãƒ»æ›´æ–°
  setup_training_repo

  # äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å–å¾—ï¼ˆHugging Face ã‹ã‚‰ã‚¯ãƒ­ãƒ¼ãƒ³ï¼‰
  download_pretrained_model

  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã®ç¢ºèªï¼‰
  setup_dataset

  # ç”»åƒã‚µã‚¤ã‚ºã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã€ä¸€æ‹¬ãƒªã‚µã‚¤ã‚ºå‡¦ç†
  resize_images

  # LoRA å­¦ç¿’ã‚’é–‹å§‹
  run_training

  # ä»®æƒ³ç’°å¢ƒã®è§£é™¤
  deactivate
}

main
