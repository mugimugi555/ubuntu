import ray
import torch
import os
import psutil
import socket

# Ray ã«æ¥ç¶š
ray.init(address="auto")

print("ğŸš€ Ray ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒ˜ãƒƒãƒ‰ãƒãƒ¼ãƒ‰ã«æ¥ç¶šã—ã¾ã—ãŸï¼")

# âœ… ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—
resources = ray.available_resources()
print("\nğŸ”¹ **Ray ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹** ğŸ”¹")
for key, value in resources.items():
    print(f"  {key}: {value}")

# âœ… CUDA ã®æƒ…å ±ã‚’å–å¾—
print("\nğŸ”¹ **CUDA ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹** ğŸ”¹")
print(f"  CUDA åˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"  ä½¿ç”¨ä¸­ã® GPU: {torch.cuda.get_device_name(0)}")
    print(f"  GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
    print(f"  GPU ãƒ¡ãƒ¢ãƒªç·å®¹é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**2:.2f} MB")

# âœ… ã‚µãƒ¼ãƒãƒ¼ã®ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—
print("\nğŸ”¹ **ã‚µãƒ¼ãƒãƒ¼æƒ…å ±** ğŸ”¹")
print(f"  ãƒ›ã‚¹ãƒˆå: {socket.gethostname()}")
print(f"  OS: {os.uname().sysname} {os.uname().release}")
print(f"  CPU ã‚³ã‚¢æ•°: {psutil.cpu_count(logical=True)}")
print(f"  ç·ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().total / 1024**3:.2f} GB")
print(f"  ä½¿ç”¨ä¸­ã®ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().used / 1024**3:.2f} GB")
print(f"  ç©ºããƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().available / 1024**3:.2f} GB")

print("\nâœ… Ray ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨ã‚µãƒ¼ãƒãƒ¼æƒ…å ±ã®å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
